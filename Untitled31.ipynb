{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, matplotlib as plt, numpy as np, pandas as pd,csv,glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import array\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r'D:\\Masters project\\Casme2\\CASME2-coding-20190701.xlsx',converters={'Subject': lambda x: str(x),'Filename': lambda x: str(x)},header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Masters project/Casme2/Cropped-updated/Cropped/sub01/EP03_02'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temppath=\"D:\\Masters project\\Casme2\\Cropped-updated\\Cropped\\\\\"\n",
    "a=np.empty(len(df1.index)-1,dtype = 'object')  #store into numpy arrays\n",
    "\n",
    "for i in range(len(df1.index)-1):\n",
    "    a[i]=(temppath+'sub'+df1.loc[i+1,0]+'\\\\'+df1.loc[i+1,1])\n",
    "    a[i]=(a[i].replace(\"\\\\\", \"/\")) \n",
    "    \n",
    "    \n",
    "a[1] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "#max no of frames\n",
    "maxframes=0\n",
    "framecount=[]\n",
    "for j in range(1,len(df1.index)):\n",
    "    result= df1.loc[j,5]-df1.loc[j,3]\n",
    "    #print(result)\n",
    "    framecount.append(result+1)\n",
    "    if result>maxframes:\n",
    "        maxframes=result+1\n",
    "    elif result==maxframes:\n",
    "        maxframes=result+1\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "print(maxframes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#framecount[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>EP02_01f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "      <td>86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>01</td>\n",
       "      <td>EP03_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131</td>\n",
       "      <td>139</td>\n",
       "      <td>161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>01</td>\n",
       "      <td>EP04_02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>01</td>\n",
       "      <td>EP04_03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>01</td>\n",
       "      <td>EP04_04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1   2    3    4    5   6   7          8\n",
       "1  01  EP02_01f NaN   46   59   86 NaN  12  happiness\n",
       "2  01   EP03_02 NaN  131  139  161 NaN  18     others\n",
       "3  01   EP04_02 NaN   21   54   76 NaN   4     others\n",
       "4  01   EP04_03 NaN   31   41   56 NaN   4     others\n",
       "5  01   EP04_04 NaN   23   49   66 NaN   4     others"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subjects array\n",
    "df=df1.drop(0)\n",
    "#print(df[0].unique())\n",
    "\n",
    "subjects=df[0].unique()\n",
    "\n",
    "df.head()\n",
    "#print(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects, counts = np.unique(df[0].values,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpath=np.empty(len(subjects),dtype = 'object')\n",
    "k=0\n",
    "for i in range(len(subjects)):\n",
    "    subpath[i]=(temppath+'sub'+subjects[k]+'\\\\')\n",
    "    #subpath[i]=(subpath[i]+df1.loc[i+1,1])\n",
    "    subpath[i]=(subpath[i].replace(\"\\\\\", \"/\"))\n",
    "    k=k+1\n",
    "        \n",
    "#subpath[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionp=[]*len(df[1])\n",
    "for i in range(len(df[1])):\n",
    "    emotionp.append(temppath+'sub'+df.iloc[i,0]+'\\\\'+df.iloc[i,1]+'/')\n",
    "    emotionp[i]=(emotionp[i].replace(\"\\\\\", \"/\"))\n",
    "#emotionp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(emotionp)):\n",
    "    pathff=[]\n",
    "    files=glob.glob(emotionp[i]+'*.jpg')\n",
    "    last=max(files,key=os.path.getctime)\n",
    "    #print(last)\n",
    "    for file in files:\n",
    "        pathff.append(file)\n",
    "        file=file.replace(\"\\\\\", \"/\")\n",
    "        #print(file)\n",
    "    #print('')\n",
    "    #print(file)\n",
    "    #print('')\n",
    "    ad=len(pathff)\n",
    "    #print(ad)\n",
    "    for j in range(maxframes-ad):\n",
    "        pathff.append(file)\n",
    "    pathd.extend(pathff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathd  #contains all the paths of frames including the padding\n",
    "for i in range(len(pathd)):\n",
    "    pathd[i]=pathd[i].replace(\"\\\\\",\"/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 141)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathd=np.reshape(pathd,(-1,141))\n",
    "pathd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "for l in range(len(df[8])):\n",
    "    label.append(df.iloc[l,8])\n",
    "#df[8].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathd=np.array(pathd)\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "for lt in range(len(label)):\n",
    "    if lt<=205:\n",
    "        y_train.append(label[lt])\n",
    "        X_train.append(pathd[lt])\n",
    "    elif lt>205 & lt<256:\n",
    "        y_test.append(label[lt])\n",
    "        X_test.append(pathd[lt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chakr\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#test and train\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "integer_encoded= le.transform(y_train)\n",
    "\n",
    "integer_encoded1= le.transform(y_test)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "integer_encoded1 = integer_encoded1.reshape(len(integer_encoded1), 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "y_train= onehot_encoder.transform(integer_encoded)\n",
    "y_test= onehot_encoder.transform(integer_encoded1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 141)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label1 = LabelBinarizer().fit_transform(label1)\n",
    "#label1\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(pathd, label1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "data_test = tf.data.Dataset.from_tensor_slices(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMG_WIDTH, IMG_HEIGHT = 224 , 224\n",
    "def process_img(img_arr):\n",
    "    #print(\"process_img acivated...\")\n",
    "    video = tf.TensorArray(tf.float32, size=141)\n",
    "    max_seq_len = (img_arr).shape[0]\n",
    "    for i in tf.range(max_seq_len):\n",
    "        #color images\n",
    "        frame_path=(img_arr)[i]\n",
    "        img = tf.io.read_file(frame_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3) \n",
    "        #convert unit8 tensor to floats in the [0,1]range\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        img=(tf.image.resize(img, [224, 224]))/255.0\n",
    "        video = video.write(i, img)\n",
    "        #t2=tf.reshape(video,[224,224])\n",
    "    return video.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_img(X_train[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.map(process_img, num_parallel_calls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test=data_test.map(process_img,num_parallel_calls=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([141, 224, 224, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.element_spec.shape\n",
    "data_test.element_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train=tf.data.Dataset.from_tensor_slices(y_train)\n",
    "label_test=tf.data.Dataset.from_tensor_slices(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((data_train, label_train))\n",
    "test_ds = tf.data.Dataset.zip((data_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(141, 224, 224, 3), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(7,), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=train_ds.batch(1).prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "test_ds=test_ds.batch(1).prefetch(tf.data.experimental.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_label(file_path):\n",
    "    for i in range(len(pathd)):\n",
    "        if pathd[i]==file_path:\n",
    "            labelss=label1[i].squeeze()\n",
    "        else:\n",
    "            pass\n",
    "    return tf.convert_to_tensor(labelss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def combine_images_labels(file_path: tf.Tensor):\n",
    "    print(\"combine_images_labels acivated...\")\n",
    "    img = tf.io.read_file(file_path)\n",
    "    print(\"image file read...\")\n",
    "    img = process_img(img)\n",
    "    #print(img.shape)\n",
    "    label2 = get_label(file_path)\n",
    "    return img,label2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def new_map(file_path:tf.Tensor):\n",
    "    video = tf.TensorArray(tf.float32, size=141)\n",
    "\n",
    "    for i in tf.range(141):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = process_img(img)\n",
    "        # Image loaded from path[i] into frame\n",
    "        video = video.write(i, img)\n",
    "\n",
    "    return video.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_train=data_train.map(lambda x: tf.py_function(func=new_map,\n",
    "          inp=[x], Tout=(tf.float32,tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_test=data_test.map(lambda x: tf.py_function(func=new_map,\n",
    "          inp=[x], Tout=(tf.float32,tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(data_train.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for image, label in data_train.take(1):\n",
    "    print(\"Image shape: \", image.shape)\n",
    "    print(\"Label: \", label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed (TimeDistri (None, 141, 222, 222, 64) 1792      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 141, 111, 111, 64) 0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 141, 109, 109, 64) 36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 141, 54, 54, 64)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 141, 52, 52, 64)   36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 141, 26, 26, 64)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 141, 24, 24, 64)   36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 141, 12, 12, 64)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 141, 10, 10, 64)   36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 141, 5, 5, 64)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 141, 1600)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               885248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,035,655\n",
      "Trainable params: 1,035,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(141, 224, 224, 3)))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Conv2D(64, (3, 3))))\n",
    "model.add(layers.TimeDistributed(layers.MaxPooling2D(2)))\n",
    "model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(7))\n",
    "model.add(layers.Softmax())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 206 steps\n",
      "Epoch 1/5\n",
      "206/206 [==============================] - 1059s 5s/step - loss: 1.9985 - categorical_accuracy: 0.3058\n",
      "Epoch 2/5\n",
      "206/206 [==============================] - 1092s 5s/step - loss: 1.6459 - categorical_accuracy: 0.3641\n",
      "Epoch 3/5\n",
      "206/206 [==============================] - 1083s 5s/step - loss: 1.6431 - categorical_accuracy: 0.3641\n",
      "Epoch 4/5\n",
      "206/206 [==============================] - 1079s 5s/step - loss: 1.6424 - categorical_accuracy: 0.3641\n",
      "Epoch 5/5\n",
      "206/206 [==============================] - 1117s 5s/step - loss: 1.6420 - categorical_accuracy: 0.3641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2e19cd80dc8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 95s 2s/step - loss: 1.5544 - categorical_accuracy: 0.3061\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.554385165778958, 0.30612245]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\Masters project\\CasmeModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classes = y_test.argmax(1)\n",
    "y_pred_classes = pred.argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30612244897959184\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_true=y_test_classes, y_pred=y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = keras.models.load_model('D:\\Masters project\\CasmeModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 106s 2s/step - loss: 1.5544 - categorical_accuracy: 0.3061\n"
     ]
    }
   ],
   "source": [
    "results1=mymodel.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "train_pred = mymodel.predict(train_ds, verbose=1)\n",
    "y_train_ground = y_train.argmax(1)\n",
    "y_train_pred = train_pred.argmax(1)\n",
    "\n",
    "train_cmat = confusion_matrix(y_train_ground, y_train_pred)\n",
    "print(train_cmat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
